[TOC]

```
1. 本书《算法第四版》从2016.12.18开始阅读。
2. 本书所有练习代码都在GitHub上维护。地址：https://github.com/FanZhouk/Algorithm.git
3. 笔记使用Typora编写，在GitHub上会有目录和公式无法显示的问题。
4. 一些章节的目录顺序可能与书中的顺序稍有不同。
5. 若Eclipse等编辑器无法导入项目，需进行以下配置：windows–>Preferences–>Team–>Git–>Configuration–>User Settings，点击Add Entry添加键值对：Key="http.sslVerify",Value="false"。
```

# 第一章 基础

## 1.1 基础编程模型

## 1.2 数据抽象

抽象数据类型（ADT），开发中会碰到很多种抽象数据类型，涉及数学的比如整数、浮点数，涉及数据结构的比如数组、链表，与现实相关的比如日期（Date）等。

使用抽象数据类型的好处在于，我们使用这些ADT的时候是面向接口编程的，即我们可以将一种实现改变为另一种实现，而无需改变调用部分的代码。

## 1.3 背包、队列和栈

**背包**：是一种不支持删除元素的集合数据类型，它的目的就是帮助用例收集元素，并迭代遍历所有收集到的元素。使用背包就说明，元素的处理顺序不重要。可以想象一个背包，往里面放了n个小球，取出的时候手伸进背包，球是随机取出来的。通常用于计算平均值等对元素顺序没有要求的算法。

**队列**：一种先进先出的数据结构，代码见：`com.fzk.adt.Queue<E>`

**栈**：一种后进先出的数据结构，代码见：`com.fzk.adt.Stack<E>`

注，这里队列和栈的代码都是利用链表实现的。

 

应用：

* **算术表达式求值**：利用Dijkstra的双栈求值法。一个栈存储操作符，另一个栈存储计算的数字。

  遇到数字就压入数字栈，遇到四则运算符就压入操作符栈，遇到右括号就弹出两个数字栈栈顶元素和操作符栈顶元素，进行计算，并压入栈。直到字符串读取完成，停止循环。

  * 代码见：`com.fzk.util.MathUtil.evaluate(String)` 

* **后序表达式求值**：只需要使用一个栈即可，它用于存储计算过程中产生的数字。

  遇到数字就压入栈，遇到操作符就弹栈计算结果并重新压入栈，这样计算结束后最后剩余的一个数字就是表达式的结果。前序表达式原理类似。

  * 代码见： `com.fzk.util.MathUtil.evaluatePostfix(String)` 

* **链表**：本处实现了双向循环链表，与 `java.util.LinkedList<E>` 类似。实现链表之后，可以轻松的利用链表来实现背包、队列、堆栈的功能。

  * 单链表的就地翻转：实现方法是，首先取到首节点和尾节点的指针，尾节点固定，首节点从头到尾移动，依次插入尾节点的下一位。但这里说的插入，仅仅是通过改变next域来实现的，并不是创建新的节点。
  * 代码见：链表：`com.fzk.adt.LinkedList<E>` ，单链表翻转： `com.fzk.adt.LinkedQueue.reverse()` 、 `com.fzk.adt.LinkedStack.reverse()` 



tips：

* **宽接口与窄接口**：在接口设计（尤其是底层代码，如数据结构的接口设计）中，我们经常会遇到“要不要这个功能”的问题。这里我们要尽量遵守一个原则：根据类的功能定义接口。不要想到什么功能就一股脑往里面添加。

  比如设计jdk中的Stack，只需要实现堆栈的基本功能就可以了，但要是为了类的“多功能”，而实现了向栈底插入元素等队列的功能，这个类就会显得不伦不类。

  我们尽量保持窄接口，是因为窄接口可以让我们清楚地明白类的功能和特性（如栈就只有入栈和出栈），限制用例的行为，使用例代码更加易懂。还有一点就是性能问题：宽接口无法保证高效的实现所有接口。

* **foreach语句**：Java中的foreach语句（如 `for (String s : list)` ），执行时会隐式创建一个迭代器，因此遍历的对象必须是实现Iterable接口的，即拥有一个返回Iterator迭代器的方法。


## 1.4 算法分析

要评价一个算法的好坏，主要看它的执行时间。比如ThreeSum问题，最容易想到的是进行三遍循环（当然还有更好的方法），那么它的运行时间是~$aN^3$。其中“~”表示与哪个数量级近似，小于该数量级的则省略；$a$表示常数，这个常数取决于计算机性能。

进行算法分析的一个好处在于，它把“算法”和“算法的实现”隔离开来。也就是说，只要算法确定了，不论是在微型计算机还是在大型计算机上，它们的算法复杂度是相同的。

特别注意，$lgN$是以2为底，而不是数学上习惯的以10为底数，因为在分析复杂度只需要精确到数量级，对于log来说底数是任何大于1的有理数都没有差别，以2为底数只是方便计算而已。

常见的增长数量级：

| 描述     | 数量级    | 算法   |   举例 |
| :----- | ------ | :--- | ---: |
| 常数级别   | $1$    | 普通语句 | 堆栈操作 |
| 对数级别   | $lgN$  | 二分策略 | 二分查找 |
| 线性级别   | $N$    | 单次循环 | 元素搜索 |
| 线性对数级别 | $NlgN$ | 分治策略 | 归并排序 |
| 平方级别   | $N^2$  | 双层循环 | 插入排序 |
| 立方级别   | $N^3$  | 三层循环 |    - |
| 指数级别   | $2^N$  | 穷举查找 |    - |

 

一个小概念：下界。下界是指一个算法在最坏情况下的时间复杂度。比如2-sum问题的下界就是$NlgN$，3-sum问题的下界是$N^2$，K-sum问题的下界是$N^{K-1}(K\geq3)$。

2-sum问题，代码见：`com.fzk.util.ArrayUtil.twoSum(int[], int)`

3-sum问题，代码见：`com.fzk.util.ArrayUtil.threeSum(int[], int)`

 

在估算算法性能时，有几点可能引起估算不准确：

* 大常数：比如对一个算法的估算是$2N^2+cN$，我们通常会简化为$N^2$。这里有一个隐藏的前提条件，即常数$c$很小。但当$c=10000$甚至更大时，显然模型就不准确了。
* 非决定性内循环。
* 指令时间：每条指令执行的时间不一定完全相同。
* 系统因素：与计算机性能、网络连接有关。
* 不分伯仲：程序在某些场景很快，在特殊场景下又很慢。
* 对输入的强烈依赖：最好情况下复杂度是常数级别，最坏就没边了。
* 多个问题参量。

## 1.5 案例研究：union-find算法

本节主要讲解并查集数据结构。并查集（Union-Find），核心功能是存储 $n$ 个节点的图结构，并存储其中的节点连通信息。

例如，并查集（图）中一共有5个节点，我们使用5个元素的数组 `int[] id = [0, 1, 2, 3, 4]` 来存储，这个数组就表示“含有5个独立连通分量的并查集数据结构”。利用这个数组还可以存储任意两个节点的连接关系。记录连接信息的算法有三种，分别见下面三小节。

并查集的API如下，其中三种算法的区别就在于 `union(int, int)` 方法和 `find(int)` 方法。

```java
public class UnitFind {
	public int[] id; // 分量ID，用于存储每个节点所属的连通分量
	private int count; // 连通分量数量

	// 在p和q之间创建一条连接
	public void union(int p, int q);
	// 获取p所在分量的标识符
	public int find(int p);
	// 判断p和q是否相连
	public boolean connected(int p, int q);
	// 获取连通分量的数量
	public int count();
}
```

### 1.5.1 quick-find算法

**算法原理**：quick-find是并查集中最容易理解的一种算法，它的特点是，数组 `id[]` 中，同一个连通分量的所有触点的值全部相同，换句话说，当且仅当 `id[p]==id[q]` 时，p和q是连通的。

比如数组 `[2, 2, 2, 2, 2, 5, 6, 9, 9, 9]` ，共有10个节点，其中第1~5个节点是互相连通的，第8~10个节点也是互相连通的。

根据以上实例我们可以看出，同一个连通分量的数值一定是相同的，因此一个分量里任意一个触点的数值就可以作为分量的标识符，即每个分量都是由它的触点之一表示的。这种表示方式的优点是，连通信息一目了然，只要数字相同的，就属于同一个连通分量。

`find(int)` 和 `union(int, int)` 方法的逻辑也很简单。`find(int)` 方法直接获取数组上对应的数字即可，`union(int, int)` 方法首先获取到两个节点所在的分量标识，若不在同一分量中，则遍历整个数组，把两个分量的数值统一即可。

**算法分析**：算法无法处理大型问题，因为每一次执行`union(int, int)` 方法都要扫描整个数组。将规模为 $n$ 的并查集归并为最后只有一个连通分量，时间复杂度为 $N^2$ ，平方级别。

代码见： `com.fzk.adt.unionFind.QuickFindUF` 

### 1.5.2 quick-union算法

**算法原理**：quick-union算法与quick-find的区别的实质在于，该算法并不是所有连通分量都共用一个标识，而是每个连通分量都形成了一棵树，只有在树的根节点处，才满足 `id[i] == i` ，即位置和数值相同。而对于树的其他节点，它们的数值会指向数组中的其他位置，如果这个位置是根节点，那么一棵树就形成了，否则可以继续向上追溯，直到根据一个叶子结点找到树的根节点。

比如 `[3, 5, 5, 4, 5, 5, 9, 1, 2, 8]` 这个数组，索引为0的位置指向了3，3指向了4，4又指向了5，因此该并查集中的树根节点就是5。而且还可以看出，整个并查集只有一个根节点，即10个节点都属于同一连通分量。

`find(int)` 方法：只要一直向上找到满足 `id[i] == i` 的条件的节点即可，这个节点就是传入节点的根节点；

`union(int, int)` 方法：分别找到两个节点的根节点，然后把其中一个根节点的数值变为另一个根节点，即把一棵树转换为另一棵树的子树。

**算法分析**：是quick-find算法的一种改进，最佳情况下，时间复杂度是线性级别，最坏情况下是平方级别。

代码见： `com.fzk.adt.unionFind.QuickUnionUF` 

### 1.5.3 加权quick-union算法

**算法原理**：是对quick-union算法的进一步优化。区别在于，该算法会记录下每一棵树的根节点的树的大小，根据这个大小，当执行union方法时，会保证永远将小树挂在大树上，这样可以保证树的深度尽量小，即find方法需要访问数组的次数尽量少。

`find(int)` 方法：与quick-union算法相同；

`union(int, int)` 方法：找到两个节点的根节点，将较小的树根挂在较大的树根下。

**算法分析**：利用加权quick-union算法，可以在最坏情况下的时间复杂度为 $lgN$ 。

代码见： `com.fzk.adt.unionFind.WeightedQuickUnionUF` 

注：书中的三个测试文件tinyUF.txt、mediumUF.txt、largeUF.txt可以在 [这里](http://algs4.cs.princeton.edu/15uf/) 下载到。

# 第二章 排序

## 2.1 初级排序算法

### 2.1.1 游戏规则

评判一种排序算法的优劣，可以通过以下两个方面：

1. 运行时间

排序成本模型：在研究排序算法时，我们需要计算“比较”和“交换”的数量。对于不交换元素的算法，我们会计算“访问数组”的次数。

2. 额外的内存使用

根据是否需要占用额外存储空间，可以将排序算法分为：就地排序算法和其他排序算法。

### 2.1.2 选择排序

**主要思想**：循环数组，找出最小的，与第一个元素交换（当第一个元素就是最小的时候，与自己交换）；找出第二小的，与第二个元素交换...直到循环整个数组。

**复杂度**：~$\frac{N^2}{2}$ 

**算法特点**：

* 运行时间与输入无关。即无论输入是有序数组还是乱序数组，比较次数是完全一样的；
* 复杂度较高；
* 是一种就地排序算法。

代码见：`com.fzk.util.SortUtil.selectionSort(int[])`

### 2.1.3 插入排序

**主要思想**：把数组分为两个区域：左边为有序区，右边为无序区。循环数组，每次取无序区的第一个，插入到有序区中的相应位置上去，比它大的元素各后移一位。直到整个数组都变为有序区为止。

**复杂度**：

* 最好情况下（输入数组严格有序），需要$N-1$次比较，$0$次插入；
* 最坏情况下（输入数组严格逆序），需要~$\frac{N^2}{2}$次比较，~$\frac{N^2}{2}$次插入；
* 平均情况下，需要~$\frac{N^2}{4}$次比较，~$\frac{N^2}{4}$次插入。



**算法特点**：

* 输入数组的好坏对算法效率影响很大；
* 适用于部分有序的数组（每个元素离它的最终位置都不远）；
* 是一种就地排序算法。



代码见：`com.fzk.util.SortUtil.insertionSort(int[])`

### 2.1.4 希尔排序

**主要思想**：多次插入排序。设定步长h，第一步使数组中任意间隔为h的元素都是有序的，形成一个h有序数组。下一步缩小步长为h/2，使数组成为一个h/2有序数组...h最后为1，对整个数组进行插入排序。

 

希尔排序是插入排序的改良版。插入排序只能一个一个元素的移动，这样效率会很慢。

 

第一步，分组。希尔排序会首先设定一个“步长”h，把索引为0,h,2h...这些元素看做一组，把索引为1,h+1,2h+1...这些元素也看做一组，以此类推。如下图所示：

![wpsB0E6.tmp.jpg](https://ooo.0o0.ooo/2017/01/01/5868fa84b255d.jpg) 

这张图表示，当数组长度为10，步长h为5时的分组情景。共分为5组（ABCDE组）。

第二步，组内排序。在每组内分别进行插入排序，如上图进行一轮组内排序后得到结果如下图。希尔排序相比直接插入排序的效率提升极大，关键就在这一步组内排序！

![wpsB0E7.tmp.jpg](https://ooo.0o0.ooo/2017/01/01/5868fa84c707b.jpg) 

第三步，缩小步长。缩小步长后重复组内排序，直到步长变为1。一般缩小步长的算法可以直接将原步长除以2。上图继续缩小步长为2，则下一次的组内排序变为下图：

![wpsB0E8.tmp.jpg](https://ooo.0o0.ooo/2017/01/01/5868fa84c9d23.jpg) 

继续缩小步长为1，如下图：

![wpsB0F8.tmp.jpg](https://ooo.0o0.ooo/2017/01/01/5868fc7845265.jpg) 

进行完步长h为1的时候，希尔排序宣告完成。

 

**算法分析**：希尔排序的关键就在于，组内排序！传统的插入排序要向有序区中间插入一个数字，只能把大于插入数字的所有元素都往后移动一位。这样太慢了！

希尔排序的做法是，首先分组，进行组内排序。第一次组内排序不要求元素一定在最终的位置上，但能保证进行一次组内排序后，每个元素都向最终的位置靠近了！

这样进行多轮组内排序，就可以完成整个算法的排序。

 

希尔排序选择插入排序做组内排序算法的原因在于，插入排序有一个极大的优点：输入数组越是接近有序，排序速度越快！最好情况可达到线性的复杂度。

而不断组内排序，就构造了一个这样的环境：数组变得越来越接近有序。这样可以让插入排序发挥它的优势。

 

> 通过提升速度来解决其他方式无法解决的问题，是研究算法的设计和性能的主要原因之一。
>
> ——名人名言

 

**复杂度**：当使用的递增序列为$3h+1$时（即1,4,13,40,121...，见代码），最坏情况下，比较次数与~$N^{\frac{3}{2}}$成正比。

使用不同的递增序列，比较的次数会各不相同，但都会小于直接插入排序的~$N^{2}$。

 

代码见：`com.fzk.util.SortUtil.shellSort(int[])`

参考链接：[白话经典算法：希尔排序](http://blog.csdn.net/morewindows/article/details/6668714)

## 2.2 归并排序

### 2.2.1 自顶向下的归并

**主要思想**：递归，合并。

假如原数组长度为$n$，先排序左半部分（$0$ ~ $\frac n 2$），再排序右半部分（$\frac n 2+1$ ~ $n-1$）。最后将这两个子数组合并。

其中两个对子数组的排序用的也是归并排序，这就体现出递归的思想。

归并排序还包含了一个重要的思想：分治思想。

**复杂度**：时间复杂度：假设原数组长度为$N$，那么需要递归$n=lgN$次。想象成树形结构，那么这棵树有$n$层。则第k层共有$2^k$个子数组，每一个子数组的长度是$2^{n-k}$，则第$k$层要比较$2^{n-k} \times 2^k=2^n$次。则每层比较的次数与层数无关。那么一共$n$ 层，共需要比较$n \times 2^n=NlgN$次。因此归并排序的时间复杂度为~$NlgN$。

空间复杂度：需要一个与原数组长度相同的辅助数组，因此空间复杂度是~$N$。

**算法优化**：

1. 用插入排序代替小数组的归并。由于归并排序是一种递归算法，因此对于递归到很小的数组（比如长度为2的子数组）时仍然使用归并排序，这样对效率略有损耗。这时对小数组采用简单的插入排序，效率会略有提升。
2. 在融合之前，判断一下数组是否已经有序。当满足条件`arr[mid] <= arr[mid+1]`的条件时，说明数组已经有序，不需要融合了。因此添加这个判断后，对于严格有序的（子）数组，可以达到线性级别的复杂度。
3. 不要复制到辅助数组。由于每次融合都经历了“从原数组融合到辅助数组，再从辅助数组复制回原数组”的过程，这样比较浪费时间。我们可以在递归调用的每个层次交换原数组和辅助数组的角色，以节省复制所有元素的时间。
4. 多路归并。普通的归并排序是把数组分为两份，分别对每个子数组归并，然后再融合。现在可以首先分成三份，进行三向归并。


代码见：`com.fzk.util.SortUtil.mergeSort(int[])` 

### 2.2.2 自底向上的归并

**主要思想**：先两两合并，再四四合并，再八八合并，直至整个数组合并完成。

假设原数组长度为$n$，首先将每一个单独的数字看做一个长度为$1$的归并单元，两两归并，保证 `arr[0] < arr[1], arr[2] < arr[3]` 等等。再进行四四归并，即将第一步排序得到的数组，每两个元素看成一组已经排好序的归并单元，将两个归并单元进行归并，保证每四个元素都是有序的。这样直至整个数组归并完成。

**适用场景**：适用于对链表的排序。

代码见：`com.fzk.util.SortUtil.mergeSort2(int[])` 

**一些题外话**：数学可证，没有任何基于比较的算法能够保证使用少于~$NlgN$次比较将长度为$N$的数组排序。而又可以证明，对于任意长度为$N$的数组，归并排序在最差情况下需要访问数组$6NlgN$次。基于以上两点，可以得出结论：归并排序是一种渐进最优的基于比较排序的算法。

 所以，不要费尽心思寻找小于$NlgN$的比较排序算法啦，找不到的！

## 2.3 快速排序

### 2.3.1 普通快速排序

**主要思想**：分治策略。

选择一个基准数（pivot），第一趟循环让所有小于pivot的值放在左边，大于pivot的值放在右边，而pivot放在最终位置。

接着递归排序左边、右边即可。

**算法优化**：

1. 切换到插入排序。大多数的递归算法，改进算法性能有以下原则：对于小数组，递归排序要比直接插入排序慢。因此当要排序数组很小的时候，可以替换为插入排序。这样第一提高了速度，第二减少了递归深度。
2. 三取样切分。由于一开始的基准数（pivot）是随意取的，因此很有可能取到最大或最小值。以下办法可以改进：在数组中任意取3个数，并计算它们的中位数，把这个中位数当成基准数。这种方法称为三取样切分。
3. 熵最优的排序。实际中经常会出现含有大量重复元素的数组。这是，一个元素全部重复的子数组就不需要继续排序了。

代码见： `com.fzk.util.SortUtil.quickSort(int[])` 

### 2.3.2 三向切分的快速排序

**主要思想**：一次遍历，将所有等于pivot的值聚在一起。

普通的快排仅仅将数组分为两部分：小于pivot的和大于pivot的（当然，还有pivot本身）；而三向切分的快排会将数组分为三部分：小于pivot、等于pivot、大于pivot。

在一次循环中，会维护三个指针，分别是： `l` 为从左向右的指针， `h` 为从右向左的指针， `i` 在 `l` 和 `h` 中间，左边都是等于pivot，右边都是未知部分，如下图所示：

![三向切分快速排序过程图](https://ooo.0o0.ooo/2017/05/19/591dcee481c45.png)

这样进行一次循环之后，可以保证将所有等于pivot的值聚集在一起，并且将小于pivot的放在左边，将大于pivot的放在右边。继续迭代左边和右边进行排序即可。

**适用场景**：适用于存在大量重复主键的数组排序，如对大量人员信息根据性别排序、根据年龄排序等。

代码见： `com.fzk.util.SortUtil.quickSort3way(int[])` 

## 2.4 优先队列

### 2.4.1 二叉堆

一种数据结构：二叉堆。

二叉堆是一种顺序存储结构，内部用数组存储，但通过简单的运算可以表示成完全二叉树的结构。

比如根节点在位置$1$（索引为0的位置为空），那么索引为$k$的元素的左节点在$2k$，右节点在$2k+1$，父节点在$\lfloor \frac k 2 \rfloor$。（这里取根节点位置是$1$，主要是为了方便子节点和父节点的运算）。

二叉堆可分为最大堆和最小堆。若将二叉堆转化为树形结构，若任何一个父节点大于它的两个子节点（如果有的话），那么它就是最大堆；若任何一个父节点小于它的两个子节点，那么就是最小堆。

以最大堆为例，存储结构如图所示：这是一个存储了10个元素的二叉堆，占用数组长度为11，右图为位置k的父节点和左右子节点位置。可以看出这是一棵完全二叉树结构。

![](https://ooo.0o0.ooo/2017/01/05/586da589b60fc.png)

### 2.4.2 优先队列

**ADT简介**：以最大优先队列为例，最大优先队列可以存储一组对象数据，主要提供以下方法：

1. 增加一个元素；
2. 删除并返回最大元素。

若用普通的顺序结构或链表结构，也能完成这样的需求，但要么插入的复杂度是~$N$，要么删除的复杂度是~$N$。

现在使用优先队列，可以使插入和删除操作的复杂度都变为$lgN$。

**主要思想**：要实现优先队列，主要实现三个方法：1）增加一个元素；2）删除最大元素；3）给二叉堆扩容。这里以最大优先队列为例，其中二叉堆是最大堆。

1. 增加一个元素：首先将这个元素添加到最后（size所处的位置，不是真正的数组最后的位置），然后将这个元素“上浮”，即只要遇到比它大的父节点，就交换，直到小于它的父节点为止。
2. 删除最大元素：由于最大堆的第一个元素就是最大元素，因此只需要删除第一个元素即可。首先用队列末尾的元素替换第一个元素，然后将刚换上来的这个元素“下沉”，即：不断的将这个元素与它的两个子节点中较大的一个交换，直到两个子节点都比它小，或没有子节点为止。
3. 给二叉堆扩容：扩容策略可以有多种，直接提升一倍容量，提升为1.5倍容量等等均可。复制数组直接用`java.util.Arrays.copyOf(T[], int)`即可。


**复杂度**：对于一个含有$N$个元素的二叉堆优先队列，插入元素操作最大需要比较$lgN+1$次，删除最大元素操作最多需要比较$2lgN$次。

**算法优化**：

1. 除了二叉堆，我们还可以利用三叉堆......任意叉堆。以三叉堆实现的最大堆为例，那么一个节点必须要大于它的三个子节点。其中位置$k$的节点的三个子节点分别为：$3k-1$，$3k$，$3k+1$，它的父节点是$\lfloor \frac{k+1}{3} \rfloor$。
2. 索引优先队列。在最大堆实现的优先队列中，一个元素一旦插入，就不能改变，因为改变会影响到这个元素的排序。如果我们有改变元素的需求，可以在插入每个元素时，给这个元素关联一个索引，并用一个（多个）平行数组来存储索引。


**最小优先队列**：与最大优先队列几乎相同，唯一的区别在于上浮和下沉的算法。最大优先队列会把大数字上浮，把小数字下沉，而最小优先队列刚好相反，把小数字上浮，把大数字下沉。

代码见：

* 最大优先队列：`com.fzk.adt.MaxPriorityQueue<E>` 
* 最小优先队列：`com.fzk.adt.MinPriorityQueue<E>` 

### 2.4.3 堆排序

**主要思想**：首先将数组“堆化”，然后依次取出最大数字放在最后，并将剩余元素重新构建为最大堆。

堆排序的第一步，“堆化”数组，即将数组构建为一个最大堆。较容易想到的办法是，从前向后执行 `swim()` 方法，这样总能保证指针左侧的数组是一个最大堆。但这样效率较低，有一种更好的方法：从数组中间位置开始，向前遍历，不断执行 `sink()` 方法。这种方法的高效之处在于，数组中间位置之前的所有元素，都有左右两个子节点（中间位置元素可能有一个）。

其实这个中间位置，指的就是数组最后一个元素的父节点所在的位置，这个位置能保证至少有一个子节点，而这个位置之前的所有元素，都有左右两个节点。因此将前一半元素进行下沉，可以节省一半的时间。如图所示：

![堆化数组](https://ooo.0o0.ooo/2017/05/24/59245dbfb3aaa.png)

假如数组长度 `arr.length = 10` ，则应该从 `parent(arr.length - 1)` 即索引为4处开始下沉，接着是3、2、1、0的下沉。这样就达到了只遍历一半数组，就将整个数组构建为最大堆的目的。

第二步较容易理解，每次取出堆的最大元素，与堆的最后一个元素交换，这样保证了这个堆的最后一个元素是最大的，此时立刻将换到最后的元素踢出最大堆（ `size--` 即可），并将换到最前的元素下沉，以形成一个新的最大堆。这样循环下去，就可以保证每次取出的都是当前堆中的最大元素，即从小到大依次排列在堆的后面。等到遍历结束，则排序完成。

**复杂度**：比较次数为 $2NlgN+2N$ ，交换次数为 $N/2$ 。

代码见： `com.fzk.util.SortUtil.heapSort(int[])` 

注：该代码中，数组索引为0的位置也被利用了，因此获取父子节点索引的方法略有区别。

## 2.5 应用

### 2.5.1 排序的特性

**指针排序**：在java中，我们不需要指定直接操作数据（值传递）还是操作数据的指针（引用传递）。java中指针操作是隐式的，只有在传递8中基本数据类型数据的时候，才是传值的（String类型也类似于值传递，即不会被改变），其他的对象在传递时都是传引用。

因此当我们排序的对象是对象时，我们交换的其实不是对象本身，只是对象的引用。因此这是一种“廉价的交换”。

**排序的稳定性**：如果一个排序算法能够保留数组中重复元素的相对位置，则被称为是稳定的。

比如我们要对订单排序，规则是根据时间和地点同时排序。可以进行的办法是，先对时间排序后，将这个结果再对地点排序。这就要求排序算法必须是稳定的，否则对地点排序后无法保证对时间也是排好序的。

本章的算法中，插入排序和归并排序是稳定的，选择排序、希尔排序、快速排序和堆排序都是不稳定的。

### 2.5.2 排序算法的比较

 **排序比较**：各种排序算法的性能特点如下表。

| 算法     | 是否稳定 | 是否就地 | 时间复杂度      | 空间复杂度 |
| :----- | :--- | :--- | :--------- | ----: |
| 选择排序   | 不稳定  | 就地   | $N^2$      |   $1$ |
| 插入排序   | 稳定   | 就地   | $N$~$N^2$  |   $1$ |
| 希尔排序   | 不稳定  | 就地   | $NlgN$     |   $1$ |
| 快速排序   | 不稳定  | 就地   | $NlgN$     | $lgN$ |
| 三向快速排序 | 不稳定  | 就地   | $N$~$NlgN$ | $lgN$ |
| 归并排序   | 稳定   | 非就地  | $NlgN$     |   $N$ |
| 堆排序    | 不稳定  | 就地   | $NlgN$     |   $1$ |

### 2.5.3 问题的规约

 规约指的是为解决某个问题而发明的算法正好可以用来解决另一种问题。对于许多算法问题，实际上都可以规约为排序的问题。

 **找出重复元素**：

若暴力解决，需要循环两遍数组，在$N^2$时间才能完成。

更好的方法是先排个序，然后找相邻重复的就可以啦！代码太简单就不写了。。。

**求中位数**：

若暴力解决，需要先排个序，然后取中间位置的元素，在$NlgN$时间内才能完成。

更好的方法是，利用快排中的`partition()`方法。这个方法的作用是将一个元素放在正确的位置上，且左边的都比它小，右边的都比它大。

首先随便取一个元素，把它放到正确位置上，要是这个位置在中间偏右，就在左边找；要是偏左，就在右边找。直到这个正确位置刚好等于中间位置。返回这个中间位置的元素即可。

代码见：`com.fzk.util.ArrayUtil.findMedian(int[])`

# 第三章 查找

## 3.1 符号表

**ADT简介**：符号表是指一种存储一组键值对的抽象数据类型。实现符号表关键要实现三个方法：1）`put(K,V)`插入键值对；2）`get(K)`根据键查找值；3）`remove(K)`根据键删除键值对。

**无序链表的实现**：即最简单的单链表。插入、查找和删除操作的复杂度都是线性级别。

**有序数组的实现**：使用一对平行数组存储。一个存储键，一个存储值。

关键在于实现`rank()`方法，它返回表中小于给定键的数量。有了它，查找、插入、删除都可以很容易地实现。而由于数组本身是有序的，使用二分查找就可以实现`rank()`方法。

**二分查找分析**：对于有序数组，二分查找的复杂度是对数级别的，最多需要$lgN+1$次比较就可以确定结果，无论是否找到。证明过程挺好的，可以多看。见第三章命题B。

## 3.2 二叉查找树

**ADT简介**：一棵二叉查找树（BST, Binary Search Tree）是一棵二叉树，其中每个节点都含有一个Comparable的键（以及相关联的值），且每个节点的键都大于其左子树中任意节点的键而小于右子树任意节点的键。即左 < 中 < 右。

在由$N$个随机键构造的二叉查找树中，查找命中平均所需的比较次数为~$2lnN$（约为$1.39lgN$）。



**主要思想**：在二叉查找树中，有几个算法是比较重要的，主要思路如下：

* <u>添加一个键值对</u>：首先从根节点开始，找到要添加或修改的位置，要是键冲突直接改变即可。不冲突的话，比这个键小就放在左边，大就放在右边。


* <u>根据键获取值</u>：从根节点开始寻找，小于当前访问节点的，就在左边找，否则就在右边找。

* <u>根据键移除键值对</u>：找到这个键所对应的节点后，分三种情况：1）它是叶子节点；2）只有一个子节点；3）有两个子节点。

  1）是叶子节点：删除叶子节点是最容易的，看它在父节点的左边还是右边，对应的指针设为空就行了；

  2）有一个子节点：也比较容易，把它的父节点和它仅有的那一个节点关联起来就好了；

  3）有两个子节点：较复杂。取它的前趋（后继也可），替换掉这个节点，然后删除这个前趋（后继）。由于前趋或后继节点最多只能有一个子节点，因此删除前趋（后继）的操作递归地可以交给1）和2）去做。

  注意：以上三种情况都要考虑是否是根节点，根节点的父节点为空，处理情况稍有不同。注意判断即可。


* <u>获取节点的前趋和后继</u>：获取前趋的方法是，若它有左子节点，那么前趋就是它左子节点的最右边一个。若没有左子节点，沿着它向上找，一旦发现它是右子节点，那么它的父节点就是原节点的前趋。后继类似。寻找前趋示意图如下。

![](https://ooo.0o0.ooo/2017/01/09/5873ac62ca3bb.png)

* <u>遍历</u>：遍历分为前序、中序、后序和层次遍历。前序是指“中-左-右”的顺序，中序是指“左-中-右”的顺序，后序是指“左-右-中”的顺序，这三个都可以利用递归轻松地写出来。层次遍历利用队列即可实现。



**性能分析**：

* 在一棵二叉查找树中，所有操作在最坏情况下所需的时间都和树的高度成正比。
* 以上几乎所有方法都可以写成递归形式，但当树的高度过大时，递归调用的栈的深度过大，可能会引发性能问题。

代码见：`com.fzk.adt.BinarySearchTree<K extends Comparable<K>, V>`

## 3.3 平衡查找树































 # 备注

[一些奇形怪状的数学符号](http://blog.csdn.net/zcf1002797280/article/details/51289555)

[网络通畅但无法提交GitHub问题](http://www.cnblogs.com/yejiurui/p/3386393.html)
