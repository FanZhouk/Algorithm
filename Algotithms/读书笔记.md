[TOC]

```
1. 本书从2016.12.18开始阅读。
2. 本书所有练习代码都在GitHub上维护。地址：https://github.com/FanZhouk/Algorithm.git
3. 笔记使用Typora编写，在GitHub上会有目录和公式无法显示的问题。
4. 一些章节的目录顺序可能与书中的顺序稍有不同。
```

# 第一章 基础

## 1.1 基础编程模型

## 1.2 数据抽象

抽象数据类型（ADT），开发中会碰到很多种抽象数据类型，涉及数学的比如整数、浮点数，涉及数据结构的比如数组、链表，与现实相关的比如日期（Date）等。

使用抽象数据类型的好处在于，我们使用这些ADT的时候是面向接口编程的，即我们可以将一种实现改变为另一种实现，而无需改变调用部分的代码。

## 1.3 背包、队列和栈

**背包**：是一种不支持删除元素的集合数据类型，它的目的就是帮助用例收集元素，并迭代遍历所有收集到的元素。使用背包就说明，元素的处理顺序不重要。可以想象一个背包，往里面放了n个小球，取出的时候手伸进背包，球是随机取出来的。通常用于计算平均值等对元素顺序没有要求的算法。

**队列**：一种先进先出的数据结构，代码见：`com.fzk.adt.Queue<E>`

**栈**：一种后进先出的数据结构，代码见：`com.fzk.adt.Stack<E>`

注，这里队列和栈的代码都是利用链表实现的。

 

应用：

**算术表达式求值**：利用Dijkstra的双栈求值法。

主要思路：一个栈存储操作符，另一个栈存储计算的数字。

遇到数字就压入数字栈，遇到四则运算符就压入操作符栈，遇到右括号就弹出两个数字栈栈顶元素和操作符栈顶元素，进行计算，并压入栈。直到字符串读取完成，停止循环。

最后为了防止连加连减等情况出现，要将栈中剩余元素进行计算。

具体讲解见1.3.1.7节，算术表达式求值。

代码见：`com.fzk.util.StringUtil.calculate(String)`

 

**链表**：本处实现了双向循环链表，与`java.util.LinkedList<E>`类似。

写出链表之后，可以轻松的利用链表来实现背包、队列、堆栈的功能。

代码见：`com.fzk.adt.LinkedList<E>`

 

tips：

**宽接口与窄接口**：在接口设计（尤其是底层代码，如数据结构的接口设计）中，我们经常会遇到“要不要这个功能”的问题。这里我们要尽量遵守一个原则：根据类的功能定义接口。不要想到什么功能就一股脑往里面添加。

比如设计jdk中的Stack，只需要实现堆栈的基本功能就可以了，但要是为了类的“多功能”，而实现了向栈底插入元素等队列的功能，这个类就会显得不伦不类。

 

我们尽量保持窄接口，是因为窄接口可以让我们清楚地明白类的功能和特性（如栈就只有入栈和出栈），限制用例的行为，使用例代码更加易懂。还有一点就是性能问题：宽接口无法保证高效的实现所有接口。

 

// TODO 练习：1.3.30 双向链表的就地逆置，代码没看懂！递归、非递归形式

// TODO 练习：1.3.50 快速出错的迭代器。利用计数器实现

## 1.4 算法分析

要评价一个算法的好坏，主要看它的执行时间。比如ThreeSum问题，最容易想到的是进行三遍循环（当然还有更好的方法），那么它的运行时间是~$aN^3$。其中“~”表示与哪个数量级近似，小于该数量级的则省略；$a$表示常数，这个常数取决于计算机性能。

进行算法分析的一个好处在于，它把“算法”和“算法的实现”隔离开来。也就是说，只要算法确定了，不论是在微型计算机还是在大型计算机上，它们的算法复杂度是相同的。

特别注意，$lgN$是以2为底，而不是数学上习惯的以10为底数，因为在分析复杂度只需要精确到数量级，对于log来说底数是任何大于1的有理数都没有差别，以2为底数只是方便计算而已。

常见的增长数量级：

| 描述     | 数量级    | 算法   |   举例 |
| :----- | ------ | :--- | ---: |
| 常数级别   | $1$    | 普通语句 | 堆栈操作 |
| 对数级别   | $lgN$  | 二分策略 | 二分查找 |
| 线性级别   | $N$    | 单次循环 | 元素搜索 |
| 线性对数级别 | $NlgN$ | 分治策略 | 归并排序 |
| 平方级别   | $N^2$  | 双层循环 | 插入排序 |
| 立方级别   | $N^3$  | 三层循环 |    - |
| 指数级别   | $2^N$  | 穷举查找 |    - |

 

一个小概念：下界。下界是指一个算法在最坏情况下的时间复杂度。比如2-sum问题的下界就是$NlgN$，3-sum问题的下界是$N^2$，K-sum问题的下界是$N^{K-1}(K\geq3)$。

2-sum问题，代码见：`com.fzk.util.ArrayUtil.twoSum(int[], int)`

3-sum问题，代码见：`com.fzk.util.ArrayUtil.threeSum(int[], int)`

 

在估算算法性能时，有几点可能引起估算不准确：

* 大常数：比如对一个算法的估算是$2N^2+cN$，我们通常会简化为$N^2$。这里有一个隐藏的前提条件，即常数$c$很小。但当$c=10000$甚至更大时，显然模型就不准确了。
* 非决定性内循环。
* 指令时间：每条指令执行的时间不一定完全相同。
* 系统因素：与计算机性能、网络连接有关。
* 不分伯仲：程序在某些场景很快，在特殊场景下又很慢。
* 对输入的强烈依赖：最好情况下复杂度是常数级别，最坏就没边了。
* 多个问题参量。

## 1.5 案例研究：union-find算法

// TODO 完全看不懂。。。



# 第二章 排序

## 2.1 初级排序算法

### 2.1.1 游戏规则

评判一种排序算法的优劣，可以通过以下两个方面：

1. 运行时间

排序成本模型：在研究排序算法时，我们需要计算“比较”和“交换”的数量。对于不交换元素的算法，我们会计算“访问数组”的次数。

2. 额外的内存使用

根据是否需要占用额外存储空间，可以将排序算法分为：就地排序算法和其他排序算法。

### 2.1.2 选择排序

**主要思想**：循环数组，找出最小的，与第一个元素交换（当第一个元素就是最小的时候，与自己交换）；找出第二小的，与第二个元素交换...直到循环整个数组。



**复杂度**：~$\frac{N^2}{2}$



**算法特点**：

* 运行时间与输入无关。即无论输入是有序数组还是乱序数组，比较次数是完全一样的；
* 复杂度较高；
* 是一种就地排序算法。

代码见：`com.fzk.util.SortUtil.selectionSort(int[])`

### 2.1.3 插入排序

**主要思想**：把数组分为两个区域：左边为有序区，右边为无序区。循环数组，每次取无序区的第一个，插入到有序区中的相应位置上去，比它大的元素各后移一位。直到整个数组都变为有序区为止。

 

**复杂度**：

* 最好情况下（输入数组严格有序），需要$N-1$次比较，$0$次插入；
* 最坏情况下（输入数组严格逆序），需要~$\frac{N^2}{2}$次比较，~$\frac{N^2}{2}$次插入；
* 平均情况下，需要~$\frac{N^2}{4}$次比较，~$\frac{N^2}{4}$次插入。



**算法特点**：

* 输入数组的好坏对算法效率影响很大；
* 适用于部分有序的数组（每个元素离它的最终位置都不远）；
* 是一种就地排序算法。



代码见：`com.fzk.util.SortUtil.insertionSort(int[])`

### 2.1.6 希尔排序

**主要思想**：多次插入排序。设定步长h，第一步使数组中任意间隔为h的元素都是有序的，形成一个h有序数组。下一步缩小步长为h/2，使数组成为一个h/2有序数组...h最后为1，对整个数组进行插入排序。

 

希尔排序是插入排序的改良版。插入排序只能一个一个元素的移动，这样效率会很慢。

 

第一步，分组。希尔排序会首先设定一个“步长”h，把索引为0,h,2h...这些元素看做一组，把索引为1,h+1,2h+1...这些元素也看做一组，以此类推。如下图所示：

![wpsB0E6.tmp.jpg](https://ooo.0o0.ooo/2017/01/01/5868fa84b255d.jpg) 

这张图表示，当数组长度为10，步长h为5时的分组情景。共分为5组（ABCDE组）。

第二步，组内排序。在每组内分别进行插入排序，如上图进行一轮组内排序后得到结果如下图。希尔排序相比直接插入排序的效率提升极大，关键就在这一步组内排序！

![wpsB0E7.tmp.jpg](https://ooo.0o0.ooo/2017/01/01/5868fa84c707b.jpg) 

第三步，缩小步长。缩小步长后重复组内排序，直到步长变为1。一般缩小步长的算法可以直接将原步长除以2。上图继续缩小步长为2，则下一次的组内排序变为下图：

![wpsB0E8.tmp.jpg](https://ooo.0o0.ooo/2017/01/01/5868fa84c9d23.jpg) 

继续缩小步长为1，如下图：

![wpsB0F8.tmp.jpg](https://ooo.0o0.ooo/2017/01/01/5868fc7845265.jpg) 

进行完步长h为1的时候，希尔排序宣告完成。

 

**算法分析**：希尔排序的关键就在于，组内排序！传统的插入排序要向有序区中间插入一个数字，只能把大于插入数字的所有元素都往后移动一位。这样太慢了！

希尔排序的做法是，首先分组，进行组内排序。第一次组内排序不要求元素一定在最终的位置上，但能保证进行一次组内排序后，每个元素都向最终的位置靠近了！

这样进行多轮组内排序，就可以完成整个算法的排序。

 

希尔排序选择插入排序做组内排序算法的原因在于，插入排序有一个极大的优点：输入数组越是接近有序，排序速度越快！最好情况可达到线性的复杂度。

而不断组内排序，就构造了一个这样的环境：数组变得越来越接近有序。这样可以让插入排序发挥它的优势。

 

> 通过提升速度来解决其他方式无法解决的问题，是研究算法的设计和性能的主要原因之一。
>
> ——名人名言

 

**复杂度**：当使用的递增序列为$3h+1$时（即1,4,13,40,121...，见代码），最坏情况下，比较次数与~$N^{\frac{3}{2}}$成正比。

使用不同的递增序列，比较的次数会各不相同，但都会小于直接插入排序的~$N^{2}$。

 

代码见：`com.fzk.util.SortUtil.shellSort(int[])`

参考链接：[白话经典算法：希尔排序](http://blog.csdn.net/morewindows/article/details/6668714)

## 2.2 归并排序

**主要思想**：递归，合并。

假如原数组长度为$n$，先排序左半部分（$0$ ~ $\frac n 2$），再排序右半部分（$\frac n 2+1$ ~ $n-1$）。最后将这两个子数组合并。

其中两个对子数组的排序用的也是归并排序，这就体现出递归的思想。

归并排序还包含了一个重要的思想：分治思想。

 

**复杂度**：时间复杂度：假设原数组长度为$N$，那么需要递归$n=lgN$次。想象成树形结构，那么这棵树有$n$层。则第k层共有$2^k$个子数组，每一个子数组的长度是$2^{n-k}$，则第$k$层要比较$2^{n-k} \times 2^k=2^n$次。则每层比较的次数与层数无关。那么一共$n$ 层，共需要比较$n \times 2^n=NlgN$次。因此归并排序的时间复杂度为~$NlgN$。

空间复杂度：需要一个与原数组长度相同的辅助数组，因此空间复杂度是~$N$。

 

**算法优化**：

1. 用插入排序代替小数组的归并。由于归并排序是一种递归算法，因此对于递归到很小的数组（比如长度为2的子数组）时仍然使用归并排序，这样对效率略有损耗。这时对小数组采用简单的插入排序，效率会略有提升。

2. 在融合之前，判断一下数组是否已经有序。当满足条件`arr[mid] <= arr[mid+1]`的条件时，说明数组已经有序，不需要融合了。因此添加这个判断后，对于严格有序的（子）数组，可以达到线性级别的复杂度。

3. 不要复制到辅助数组。由于每次融合都经历了“从原数组融合到辅助数组，再从辅助数组复制回原数组”的过程，这样比较浪费时间。我们可以在递归调用的每个层次交换原数组和辅助数组的角色，以节省复制所有元素的时间。

4. 多路归并。普通的归并排序是把数组分为两份，分别对每个子数组归并，然后再融合。现在可以首先分成三份，进行三向归并。




**一些题外话**：数学可证，没有任何基于比较的算法能够保证使用少于~$NlgN$次比较将长度为$N$的数组排序。而又可以证明，对于任意长度为$N$的数组，归并排序在最差情况下需要访问数组$6NlgN$次。基于以上两点，可以得出结论：归并排序是一种渐进最优的基于比较排序的算法。

 所以，不要费尽心思寻找小于$NlgN$的比较排序算法啦，找不到的！

代码见：`com.fzk.util.SortUtil.mergeSort(int[])`

## 2.3 快速排序

**主要思想**：分治策略。

选择一个基准数（pivot），第一趟循环让所有小于pivot的值放在左边，大于pivot的值放在右边，而pivot放在最终位置。

接着递归排序左边、右边即可。

 

**算法优化**：

1. 切换到插入排序。大多数的递归算法，改进算法性能有以下原则：对于小数组，递归排序要比直接插入排序慢。因此当要排序数组很小的时候，可以替换为插入排序。这样第一提高了速度，第二减少了递归深度。
2. 三取样切分。由于一开始的基准数（pivot）是随意取的，因此很有可能取到最大或最小值。以下办法可以改进：在数组中任意取3个数，并计算它们的中位数，把这个中位数当成基准数。这种方法称为三取样切分。
3. 熵最优的排序。实际中经常会出现含有大量重复元素的数组。这是，一个元素全部重复的子数组就不需要继续排序了。

## 2.4 优先队列

### 2.4.1 二叉堆

一种数据结构：二叉堆。

二叉堆是一种顺序存储结构，内部用数组存储，但通过简单的运算可以表示成完全二叉树的结构。

比如根节点在位置$1$（索引为0的位置为空），那么索引为$k$的元素的左节点在$2k$，右节点在$2k+1$，父节点在$\lfloor \frac k 2 \rfloor$。（这里取根节点位置是$1$，主要是为了方便子节点和父节点的运算）。

二叉堆可分为最大堆和最小堆。若将二叉堆转化为树形结构，若任何一个父节点大于它的两个子节点（如果有的话），那么它就是最大堆；若任何一个父节点小于它的两个子节点，那么就是最小堆。

存储结构如图所示：这是一个存储了10个元素的二叉堆，占用数组长度为11，右图为位置k的父节点和左右子节点位置。可以看出这是一棵完全二叉树结构。

![](https://ooo.0o0.ooo/2017/01/05/586da589b60fc.png)

### 2.4.2 优先队列

**ADT简介**：优先队列是一种这样的抽象数据类型：它可以存储一组对象数据，主要提供以下方法：

1. 增加一个元素；
2. 删除并返回最大元素。

若用普通的顺序结构或链表结构，也能完成这样的需求，但要么插入的复杂度是~$N$，要么删除的复杂度是~$N$。

现在使用优先队列，可以使插入和删除操作的复杂度都变为$lgN$。

 

 **主要思想**：要实现优先队列，主要实现三个方法：1）增加一个元素；2）删除最大元素；3）给二叉堆扩容。这里以最大优先队列为例，其中二叉堆是最大堆。

1. 增加一个元素：首先将这个元素添加到最后（size所处的位置，不是真正的数组最后的位置），然后将这个元素“上浮”，即只要遇到比它大的父节点，就交换，直到小于它的父节点为止。
2. 删除最大元素：由于最大堆的第一个元素就是最大元素，因此只需要删除第一个元素即可。首先用队列末尾的元素替换第一个元素，然后将刚换上来的这个元素“下沉”，即：不断的将这个元素与它的两个子节点中较大的一个交换，直到两个子节点都比它小，或没有子节点为止。
3. 给二叉堆扩容：扩容策略可以有多种，直接提升一倍容量，提升为1.5倍容量等等均可。复制数组直接用`java.util.Arrays.copyOf(T[], int)`即可。




**复杂度**：对于一个含有$N$个元素的二叉堆优先队列，插入元素操作最大需要比较$lgN+1$次，删除最大元素操作最多需要比较$2lgN$次。



**算法优化**：

1. 除了二叉堆，我们还可以利用三叉堆......任意叉堆。以三叉堆实现的最大堆为例，那么一个节点必须要大于它的三个子节点。其中位置$k$的节点的三个子节点分别为：$3k-1$，$3k$，$3k+1$，它的父节点是$\lfloor \frac{k+1}{3} \rfloor$。
2. 索引优先队列。在最大堆实现的优先队列中，一个元素一旦插入，就不能改变，因为改变会影响到这个元素的排序。如果我们有改变元素的需求，可以在插入每个元素时，给这个元素关联一个索引，并用一个（多个）平行数组来存储索引。



代码见：`com.fzk.adt.MaxPriorityQueue<E>`

### 2.4.3 堆排序

**堆排序**：给定一个数组，首先把这个数组进行“堆化”，即构建一个最小堆。方法是：从右至左的调用`sink()`方法。

//TODO 有些不理解

## 2.5 应用

### 2.5.1 排序的特性

**指针排序**：在java中，我们不需要指定直接操作数据（值传递）还是操作数据的指针（引用传递）。java中指针操作是隐式的，只有在传递8中基本数据类型数据的时候，才是传值的（String类型也类似于值传递，即不会被改变），其他的对象在传递时都是传引用。

因此当我们排序的对象是对象时，我们交换的其实不是对象本身，只是对象的引用。因此这是一种“廉价的交换”。

**排序的稳定性**：如果一个排序算法能够保留数组中重复元素的相对位置，则被称为是稳定的。

比如我们要对订单排序，规则是根据时间和地点同时排序。可以进行的办法是，先对时间排序后，将这个结果再对地点排序。这就要求排序算法必须是稳定的，否则对地点排序后无法保证对时间也是排好序的。

本章的算法中，插入排序和归并排序是稳定的，选择排序、希尔排序、快速排序和堆排序都是不稳定的。

### 2.5.2 排序算法的比较

 **排序比较**：各种排序算法的性能特点如下表。

| 算法     | 是否稳定 | 是否就地 | 时间复杂度      | 空间复杂度 |
| :----- | :--- | :--- | :--------- | ----: |
| 选择排序   | 不稳定  | 就地   | $N^2$      |   $1$ |
| 插入排序   | 稳定   | 就地   | $N$~$N^2$  |   $1$ |
| 希尔排序   | 不稳定  | 就地   | $NlgN$     |   $1$ |
| 快速排序   | 不稳定  | 就地   | $NlgN$     | $lgN$ |
| 三向快速排序 | 不稳定  | 就地   | $N$~$NlgN$ | $lgN$ |
| 归并排序   | 稳定   | 非就地  | $NlgN$     |   $N$ |
| 堆排序    | 不稳定  | 就地   | $NlgN$     |   $1$ |

### 2.5.3 问题的规约

 规约指的是为解决某个问题而发明的算法正好可以用来解决另一种问题。对于许多算法问题，实际上都可以规约为排序的问题。

 **找出重复元素**：

若暴力解决，需要循环两遍数组，在$N^2$时间才能完成。

更好的方法是先排个序，然后找相邻重复的就可以啦！代码太简单就不写了。。。

**求中位数**：

若暴力解决，需要先排个序，然后取中间位置的元素，在$NlgN$时间内才能完成。

更好的方法是，利用快排中的`partition()`方法。这个方法的作用是将一个元素放在正确的位置上，且左边的都比它小，右边的都比它大。

首先随便取一个元素，把它放到正确位置上，要是这个位置在中间偏右，就在左边找；要是偏左，就在右边找。直到这个正确位置刚好等于中间位置。返回这个中间位置的元素即可。

代码见：`com.fzk.util.ArrayUtil.findMedian(int[])`

# 第三章 查找

## 3.1 符号表

**ADT简介**：符号表是指一种存储一组键值对的抽象数据类型。实现符号表关键要实现三个方法：1）`put(K,V)`插入键值对；2）`get(K)`根据键查找值；3）`remove(K)`根据键删除键值对。

**无序链表的实现**：即最简单的单链表。插入、查找和删除操作的复杂度都是线性级别。

**有序数组的实现**：使用一对平行数组存储。一个存储键，一个存储值。

关键在于实现`rank()`方法，它返回表中小于给定键的数量。有了它，查找、插入、删除都可以很容易地实现。而由于数组本身是有序的，使用二分查找就可以实现`rank()`方法。

**二分查找分析**：对于有序数组，二分查找的复杂度是对数级别的，最多需要$lgN+1$次比较就可以确定结果，无论是否找到。证明过程挺好的，可以多看。见第三章命题B。

## 3.2 二叉查找树

一棵二叉查找树（BST, Binary Search Tree）是一棵二叉树，其中每个节点都含有一个Comparable的键（以及相关联的值），且每个节点的键都大于其左子树中任意节点的键而小于右子树任意节点的键。即左 < 中 < 右。

在由$N$个随机键构造的二叉查找树中，查找命中平均所需的比较次数为~$2lnN$（约为$1.39lgN$）。

代码见：`com.fzk.adt.BinarySearchTree<K extends Comparable<K>, V>`

































 # 备注

[一些奇形怪状的数学符号](http://blog.csdn.net/zcf1002797280/article/details/51289555)

[网络通畅但无法提交GitHub问题](http://www.cnblogs.com/yejiurui/p/3386393.html)
